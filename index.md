# Secure AI Framework

The AI Village sits on the intersection of machine learning and cyber security. While there is great interest in this field, there are very few people who are real experts. The field is growing rapidly, and there are lots of attempts to both discover and address potential new vulnerabilities. We want to help organizations stay ahead of threats and inform them of what really matters in ML security. Most of it is traditional security, but there are novel aspects to ML security. These are the exciting parts that have received the most attention, both from academics and industry. 

The fundamental issue with the discussion around AI security is that the academics who really understand the ML don’t understand threat models, and the security people who do understand threat models don’t know AI. For the general public adversarial examples are all they know about AI security. There are both companies offering to sell you products that will protect you from adversarial examples as well as substantial research in hardening deep learning models against them. Most of us who work in the intersection of security and ML believe that adversarial examples are a great tool to use to understand how ML works, but are in most cases a security red herring. There are many more effective and cheaper methods to bypass a model.

One highly effective tool for communicating cyber security threats is the MITRE ATT&CK matrix. Microsoft & MITRE just published a framework for AI security. 11 organizations have reviewed it, including IBM, NVIDIA, Bosch, Airbus. It’s a first draft, and hasn’t been vetted by the community. We feel like this is a perfect opportunity to address the issues we’ve seen. We want to equip as many people as possible to contribute to the framework, and help improve it. 


## Vision & Threats, Friday May 7th 2021
#### 9:00-9:10 AM (PST): Introduction

#### 9:10 - 9:30 AM (PST): Short Talks

- Grant Baumbach, AI Security Principal at Verizon

#### 9:30-9:45 AM (PST): Q&A about the talks

A panel consisting of the speakers where the moderator uses these questions for the speakers. 

#### 9:45 - 10:30 AM (PST): Breakout Session

- What’s the most valuable target?
- What’s the biggest threat to your models?
- What’s the least significant threat to your models?

#### 10:30-11:00 AM (PST): Rejoin and report out

Moderator for each room gives a brief summary of what they discussed

## Defenses, Friday May 14th 2021

#### 9:00-9:10 AM (PST): Introduction

#### 9:10 - 9:30 AM (PST): Short Talks

#### 9:30-9:45 AM (PST): Q&A about the talks

#### 9:45 - 10:30 AM (PST): Breakout Session

- What’s the simplest defense?
- What’s the most effective defense?
- What is practically possible?

#### 10:30-11:00 AM (PST): Rejoin and report out

## Implementation, Friday May 21th 2021

#### 9:00-9:10 AM (PST): Introduction

#### 9:10 - 9:30 AM (PST): Short Talks

#### 9:30-9:45 AM (PST): Q&A about the talks

#### 9:45 - 10:30 AM (PST): Breakout Session

- Who needs to hear this?
- What’s the best way to reach each audience?
- What tools are missing?

#### 10:30-11:00 AM (PST): Rejoin and report out
