# Secure AI Framework

Secure machine learning has attracted a lot of interest the last few years. Most of the work has centered around attacks, 
as we cannot build a defense without an idea of what we're defending against. Also, there are classes of attacks that may
be impossible to defend against (Cite Carlini's evisceration). 

There are some sensible defenses against existing attacks. Rate limiting an API and hiding the prediction values would 
have prevented ProofPoint's CVE (https://nvd.nist.gov/vuln/detail/CVE-2019-20634). There are also attacks that may be 
impractical to execute in any setting that we don't need to defend against. 

We want to discuss the threat landscape and come up with deployment recommendations for ML researchers and engineers that 
will minimize their threat exposure. 


## Vision & Threats, Friday May 7th 2021
#### 9:00-9:10 AM (PST): Introduction

#### 9:10 - 9:30 AM (PST): Short Talks

- Grant Baumbach, AI Security Principal at Verizon

#### 9:30-9:45 AM (PST): Q&A about the talks

#### 9:45 - 10:30 AM (PST): Breakout Session

- What’s the most valuable target?
- What’s the biggest threat to your models?
- What’s the least significant threat to your models?

#### 10:30-11:00 AM (PST): Rejoin and report out

Moderator for each room gives a brief summary of what they discussed

## Defenses, Friday May 14th 2021

#### 9:00-9:10 AM (PST): Introduction

#### 9:10 - 9:30 AM (PST): Short Talks

#### 9:30-9:45 AM (PST): Q&A about the talks

#### 9:45 - 10:30 AM (PST): Breakout Session

- What’s the simplest defense?
- What’s the most effective defense?
- What is practically possible?

#### 10:30-11:00 AM (PST): Rejoin and report out

## Implementation, Friday May 21th 2021

#### 9:00-9:10 AM (PST): Introduction

#### 9:10 - 9:30 AM (PST): Short Talks

#### 9:30-9:45 AM (PST): Q&A about the talks

#### 9:45 - 10:30 AM (PST): Breakout Session

- Who needs to hear this?
- What’s the best way to reach each audience?
- What tools are missing?

#### 10:30-11:00 AM (PST): Rejoin and report out
